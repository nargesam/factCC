[Params]
# tokenizer_mode = bert-base-cased
# classification_mode = bert-base-cased
dataset = data/processed/paired_data/data-clipped/data-train.jsonl
csvfile =  /Users/ns5kn/Documents/insight/projects/factCC/data/interim/sample_train_1k_fromclipped.csv
testcsvfile = /Users/ns5kn/Documents/insight/projects/factCC/data/interim/sample_train_1k_fromclipped_test.csv
# data/interim/sample_train_fromclipped.csv
#  ~/Documents/insight/projects/factCC/data/interim/sample_train_1k_fromclipped.csv
cache_dir = /Users/ns5kn/Documents/insight/projects/factCC/data/interim/model_cache
tf_cache_dir = /Users/ns5kn/Documents/insight/projects/factCC/data/interim/tf_cache
save_model_dir = /Users/ns5kn/Documents/insight/projects/factCC/models/saved_models
datasize = 0.01perc

max_features = 25000  
maxlen = 512  
batchsize = 2
num_epochs = 2
steps = 5
