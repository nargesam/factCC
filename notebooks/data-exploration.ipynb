{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the main data-train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/ns5kn/Documents/insight/projects/factcc/data/processed/paired_data/data-clipped/data-train.jsonl'\n",
    "\n",
    "with open(path) as f:\n",
    "            dataset = [json.loads(line) for line in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "dict_keys(['label', 'noise', 'backtranslation', 'extraction_span', 'claim', 'augmentation', 'augmentation_span', 'id', 'filepath', 'text'])\n",
      "1003355\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))\n",
    "\n",
    "print(dataset[0].keys())\n",
    "\n",
    "# ['id', 'claim', 'label', 'extraction_span', 'backtranslation', 'augmentation', 'augmentation_span', 'noisy', 'filepath', 'text']\n",
    "\n",
    "\n",
    "print(len(dataset)) \n",
    "# 1003355"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset, columns =['id', 'claim', 'label', 'extraction_span', 'backtranslation', 'augmentation', 'augmentation_span', 'noisy', 'filepath', 'text'], dtype = float) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REFUTES     503732\n",
       "SUPPORTS    499623\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 939871 (~1/2) of the data has no augmentation applied to them. 1/2 had some sort of augmentation\n",
    "# EntitySwap         151403\n",
    "# NegateSentences    142225\n",
    "# PronounSwap        111441\n",
    "# NumberSwap          98663\n",
    "\n",
    "df.augmentation.unique() #[None, 'EntitySwap', 'NegateSentences', 'PronounSwap', 'NumberSwap']\n",
    "df['augmentation'].nunique()\n",
    "df['augmentation'].value_counts()\n",
    "\n",
    "# df['augmentation'].isnull().sum() \n",
    "\n",
    "df['label'].value_counts()\n",
    "\n",
    "# REFUTES     503732\n",
    "# SUPPORTS    499623"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train = df.sample(frac=0.1, replace=True, random_state=1)\n",
    "\n",
    "len(sample_train)\n",
    "sample_train.to_csv('/Users/ns5kn/Documents/insight/projects/factcc/data/interim/sample_train_fromclipped.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train25 = df.sample(frac=0.25, replace=True, random_state=1)\n",
    "\n",
    "sample_train25.to_csv('/Users/ns5kn/Documents/insight/projects/factcc/data/interim/sample_train_250_fromclipped.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003\n"
     ]
    }
   ],
   "source": [
    "sample_train_01 = df.sample(frac=0.001, replace=True, random_state=1)\n",
    "print(len(sample_train_01))\n",
    "\n",
    "sample_train_01.columns\n",
    "\n",
    "# sample_train_01.head()\n",
    "sample_train_01.to_csv('/Users/ns5kn/Documents/insight/projects/factcc/data/interim/sample_train_1k_fromclipped.csv', header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Sample saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('/Users/ns5kn/Documents/insight/projects/factcc/data/interim/sample_train_fromclipped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REFUTES     50431\n",
      "SUPPORTS    49905\n",
      "Name: label, dtype: int64\n",
      "100336\n",
      "EntitySwap         15072\n",
      "NegateSentences    14260\n",
      "PronounSwap        11144\n",
      "NumberSwap          9955\n",
      "Name: augmentation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['label'].value_counts())\n",
    "print(len(train))\n",
    "print(train['augmentation'].value_counts())\n",
    "\n",
    "# REFUTES     50431\n",
    "# SUPPORTS    49905\n",
    "# Name: label, dtype: int64\n",
    "\n",
    "# 100336\n",
    "\n",
    "# EntitySwap         15072\n",
    "# NegateSentences    14260\n",
    "# PronounSwap        11144\n",
    "# NumberSwap          9955"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Validation set - Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path = '/Users/ns5kn/Documents/insight/projects/factcc/data/processed/paired_data/manual/val_manual.jsonl'\n",
    "\n",
    "with open(path) as f:\n",
    "            dataset = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['claim', 'label', 'filepath', 'id', 'text'])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1].keys())\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# d = pd.DataFrame(dataset, columns = ['claim', 'label', 'filepath', 'id', 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out the pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = pd.read_pickle(r'/Users/ns5kn/Documents/insight/projects/factcc/models/saved_models/29-csvfile_5batch_7epoch/history.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loss', 'accuracy', 'val_loss', 'val_accuracy'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(d)\n",
    "\n",
    "data.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
